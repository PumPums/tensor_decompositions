{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example is based on CIFAR-100 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"IS_DECOMPOSED\"] = \"0\" # not decomposed model\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from td import Conv2dTD\n",
    "from train_utils import ConvBnAct, train_model, eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.CIFAR100('data_train', train=True, download=True, transform=tt), batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.CIFAR100('data_test', train=False, download=True, transform=tt), batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader, 'test': test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model with different kernel_size\n",
    "class AModel(nn.Module):\n",
    "    def __init__(self, cls=100, conv_layer=Conv2dTD):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBnAct(3, 64, kernel_size=(5, 3), stride=2, padding=(2, 1),\n",
    "                               conv_layer=conv_layer)\n",
    "        self.conv2 = ConvBnAct(64, 128, kernel_size=(3, 4), stride=2, padding=(1, 1), bias=True, \n",
    "                               conv_layer=conv_layer)\n",
    "        self.conv3 = ConvBnAct(128, 256, kernel_size=(2, 3), stride=2, padding=(0, 1), \n",
    "                               conv_layer=conv_layer)\n",
    "        # conv with defined ranks\n",
    "        self.conv4 = ConvBnAct(256, 512, kernel_size=(5, 2), stride=2, padding=(2, 0), bias=True, \n",
    "                               conv_layer=conv_layer, core_ranks=[32, 32], stick_rank=32)\n",
    "        self.conv5 = ConvBnAct(512, 256, kernel_size=(2, 2), padding=(1, 1), stride=1, \n",
    "                               conv_layer=conv_layer)\n",
    "        self.linear = nn.Sequential(nn.Flatten(), nn.Linear(2304, cls))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0001, lr=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = train_model(model, device, optimizer, dataloaders, num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), 'model_original.pth')\n",
    "model.load_state_dict(torch.load('model_original.pth'))\n",
    "# model.load_state_dict(torch.load('model_dec.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.4147\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, device, dataloaders[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_model(model, mode=1):\n",
    "    \"\"\"Recursion to call .decompose method in conv layers\"\"\"\n",
    "    for name, layers in model.named_children():\n",
    "        try:\n",
    "            if not layers.is_decomposed:\n",
    "                layers.decompose(mode=mode)\n",
    "                # # Example of how you might set core ranks and stick ranks\n",
    "                # in_ch = layers.in_channels\n",
    "                # out_ch = layers.out_channels\n",
    "                # core_ranks = [in_ch // 2, out_ch // 4]\n",
    "                # stick_rank = min(in_ch, out_ch)\n",
    "                # layers.decompose(core_ranks=core_ranks, stick_rank=stick_rank)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        if layers is not None:\n",
    "            decompose_model(layers, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_decomp(mode=1, num_epochs=1):\n",
    "    model = AModel().to(device)\n",
    "    model.load_state_dict(torch.load('model_original.pth'))\n",
    "    print(\"Model parameters: \", sum(tensor.numel() for tensor in model.parameters()))\n",
    "    print(\"Model Eval:\")\n",
    "    eval_model(model, device, dataloaders['test'])\n",
    "    # decomposition\n",
    "    decompose_model(model, mode=mode)\n",
    "    print(\"\\nDecomposed model parameters: \", sum(tensor.numel() for tensor in model.parameters()))\n",
    "    print(\"Decomposed model Eval:\")\n",
    "    eval_model(model, device, dataloaders['test'])\n",
    "    # finetune\n",
    "    print(f\"\\nFinetune {num_epochs} epoch:\")\n",
    "    _ = train_model(model, device, optimizer, dataloaders, num_epochs=num_epochs)\n",
    "    torch.save(model.state_dict(), 'model_dec.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  2366372\n",
      "Model Eval:\n",
      "Model test accuracy: 0.4147\n",
      "\n",
      "Decomposed model parameters:  863140\n",
      "Decomposed model Eval:\n",
      "Model test accuracy: 0.2223\n",
      "\n",
      "Finetune 1 epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train process:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1 train loss: 2.860                   <-> accuracy: 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1 test loss: 3.604                   <-> accuracy: 0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "check_decomp(mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  2366372\n",
      "Model Eval:\n",
      "Model test accuracy: 0.4147\n",
      "\n",
      "Decomposed model parameters:  1010596\n",
      "Decomposed model Eval:\n",
      "Model test accuracy: 0.2955\n",
      "\n",
      "Finetune 1 epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train process:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1 train loss: 1.696                   <-> accuracy: 0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1 test loss: 3.246                   <-> accuracy: 0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "check_decomp(mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  2366372\n",
      "Model Eval:\n",
      "Model test accuracy: 0.4147\n",
      "\n",
      "Decomposed model parameters:  878500\n",
      "Decomposed model Eval:\n",
      "Model test accuracy: 0.2078\n",
      "\n",
      "Finetune 1 epoch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train process:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1 train loss: 2.892                   <-> accuracy: 0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1 test loss: 3.672                   <-> accuracy: 0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "check_decomp(mode=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo upload decomposed weights from checkpoint, you need to export \\nthe environment variable with the previously chosen mode.\\n\\nexport IS_DECOMPOSED=2 \\nor\\nimport os\\nos.environ[\"IS_DECOMPOSED\"] = 2 # mode\\n\\nThen, all decomposed weights will be loaded correctly from the checkpoint.\\nmodel.load_state_dict(torch.load(\\'model_dec.pth\\'))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To upload decomposed weights from checkpoint, you need to export \n",
    "the environment variable with the previously chosen mode.\n",
    "\n",
    "export IS_DECOMPOSED=2 \n",
    "or\n",
    "import os\n",
    "os.environ[\"IS_DECOMPOSED\"] = 2 # mode\n",
    "\n",
    "Then, all decomposed weights will be loaded correctly from the checkpoint.\n",
    "model.load_state_dict(torch.load('model_dec.pth'))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
